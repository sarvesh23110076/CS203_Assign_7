{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "CS203_ASSIGN7",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvesh23110076/CS203_Assign_7/blob/main/CS203_ASSIGN7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>CS203 : Software Tools and Techniques fo AI </B><br>\n",
        "<B>LAB7 Assignment</B><br>\n",
        "<B>Group Number : 08<Br>\n",
        "<B>Group Members :</B><br>\n",
        "<B>Sarvesh Pravin Chaudhari (<I>23110076</I>)<br>\n",
        "Afraz Azeem (<I>23110019</I>)<B>"
      ],
      "metadata": {
        "_uuid": "41cb1cf5-5fcd-4767-8423-60dec64d01ea",
        "_cell_guid": "a8403cc7-1b2f-48c6-8d13-99c9c63443c4",
        "trusted": true,
        "collapsed": false,
        "id": "hN6rxwiNTNss",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "_uuid": "899c7413-b73b-4fd6-8efd-f7541757481e",
        "_cell_guid": "b6e960b8-912d-4ecb-9bb0-0fbda9a887ac",
        "trusted": true,
        "id": "mnT64hUWv7fp",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:28.764168Z",
          "iopub.execute_input": "2025-03-15T17:56:28.764494Z",
          "iopub.status.idle": "2025-03-15T17:56:45.680464Z",
          "shell.execute_reply.started": "2025-03-15T17:56:28.764454Z",
          "shell.execute_reply": "2025-03-15T17:56:45.679793Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Dataset Preparation (10%)**"
      ],
      "metadata": {
        "_uuid": "7b9ddac4-539f-41eb-9f6c-9a880e5a621f",
        "_cell_guid": "e7527eef-3e06-4e91-9ee4-cc2fddf52cbe",
        "trusted": true,
        "collapsed": false,
        "id": "_aX--nJ8TcJx",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Load the training dataset and test data (Dataset 1)<br>\n",
        "Use 20% of the training dataset as the validation set."
      ],
      "metadata": {
        "_uuid": "ebe13038-80f1-4fd5-b4fd-b47e03101b1f",
        "_cell_guid": "9374dac9-fad8-4e28-bb4c-fdd17237233f",
        "trusted": true,
        "collapsed": false,
        "id": "FMb-afQ0ThxH",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset 1\n",
        "url1=\"https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/train.tsv\"\n",
        "url2=\"https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/test.tsv\"\n",
        "# url3=\"https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/dev.tsv\"\n",
        "\n",
        "data1=pd.read_csv(url1, sep='\\t', header=None, names=['sentence', 'label'])\n",
        "data1_train, data1_val=train_test_split(data1, test_size=0.2, random_state=42)\n",
        "data1_test=pd.read_csv(url2, sep='\\t', header=None, names=['sentence', 'label'])\n",
        "# data1_val=pd.read_csv(url3, sep='\\t', header=None, names=['sentence', 'label'])\n",
        "\n",
        "print(f\"Training samples: {len(data1_train)}\")\n",
        "print(f\"Test samples: {len(data1_test)}\")\n",
        "print(f\"Validation samples: {len(data1_val)}\")"
      ],
      "metadata": {
        "_uuid": "cf37b6f6-5da4-4fda-8252-01fa9003d1a1",
        "_cell_guid": "f349e960-4195-4631-93a5-3178e96f0dc1",
        "trusted": true,
        "id": "zFDbWSDCyaF5",
        "outputId": "3d764bf8-b137-4c32-dce5-bbdc18cf73c9",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:45.682164Z",
          "iopub.execute_input": "2025-03-15T17:56:45.682647Z",
          "iopub.status.idle": "2025-03-15T17:56:46.027628Z",
          "shell.execute_reply.started": "2025-03-15T17:56:45.682623Z",
          "shell.execute_reply": "2025-03-15T17:56:46.026632Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training samples: 5536\nTest samples: 1821\nValidation samples: 1384\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Also, the IMDB dataset (Dataset 2) can be used for continual learning.<br>\n",
        "Use 20% of the training dataset as the validation set."
      ],
      "metadata": {
        "_uuid": "08b673c8-1151-40b6-b40c-842895974b9c",
        "_cell_guid": "e9e1466a-77e2-476c-a14b-acfb33df2a14",
        "trusted": true,
        "collapsed": false,
        "id": "iNQwXFhQTmTk",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset 2\n",
        "url4=\"https://raw.githubusercontent.com/Ankit152/IMDB-sentiment-analysis/master/IMDB-Dataset.csv\"\n",
        "data2=pd.read_csv(url4)\n",
        "\n",
        "data2_temp, data2_test=train_test_split(data2, test_size=0.2, random_state=42)\n",
        "data2_train, data2_val = train_test_split(data2_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nDataset 2:\")\n",
        "print(f\"Training samples: {len(data2_train)}\")\n",
        "print(f\"Test samples: {len(data2_test)}\")\n",
        "print(f\"Validation samples: {len(data2_val)}\")"
      ],
      "metadata": {
        "_uuid": "837a4e32-84ca-4d03-aec4-8dd5dd2037d3",
        "_cell_guid": "e99c7f0b-ea7a-4588-8db3-bbe884d16fc0",
        "trusted": true,
        "id": "smL_BXmiyxCF",
        "outputId": "2be1cd6a-a5be-4cbd-8cc7-d73c49c03495",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:46.028948Z",
          "iopub.execute_input": "2025-03-15T17:56:46.029194Z",
          "iopub.status.idle": "2025-03-15T17:56:46.966253Z",
          "shell.execute_reply.started": "2025-03-15T17:56:46.029173Z",
          "shell.execute_reply": "2025-03-15T17:56:46.96542Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nDataset 2:\nTraining samples: 32000\nTest samples: 10000\nValidation samples: 8000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Construct a Multi-Layer Perceptron (MLP) model. (20%)**"
      ],
      "metadata": {
        "_uuid": "ffd543c6-5fd8-42bc-a069-38c140e9843a",
        "_cell_guid": "837cff17-ce6f-46e4-8c89-63a360e5827c",
        "trusted": true,
        "collapsed": false,
        "id": "1oumPGuHTy3n",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "_uuid": "f6415db8-af04-484b-a113-6a5a2e798cc4",
        "_cell_guid": "f9facb48-6611-4de2-9733-6ec7ac1e3aed",
        "trusted": true,
        "id": "H1qGAHZx33Aj",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:46.967029Z",
          "iopub.execute_input": "2025-03-15T17:56:46.967268Z",
          "iopub.status.idle": "2025-03-15T17:56:48.194189Z",
          "shell.execute_reply.started": "2025-03-15T17:56:46.967248Z",
          "shell.execute_reply": "2025-03-15T17:56:48.193518Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The parameter should be with:<br>\n",
        "hidden_sizes=[512, 256, 128, 64]<br>\n",
        "Output should have two labels."
      ],
      "metadata": {
        "_uuid": "15d95380-f680-48c6-9d0b-f1572292ec12",
        "_cell_guid": "0c269e3f-98b2-48ed-bf7e-73969d62bf86",
        "trusted": true,
        "collapsed": false,
        "id": "dmj92bbiTxiG",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the MLP model\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes=[512, 256, 128, 64], output_size=2, dropout_prob=0.3):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.fc5 = nn.Linear(hidden_sizes[3], output_size)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc5(x)\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "_uuid": "8557280b-f5db-4f65-a21f-5fdc7f5fe746",
        "_cell_guid": "bfb1eab9-df11-41d6-a72b-9c457854411d",
        "trusted": true,
        "id": "xLSIDfxOOf82",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:48.194934Z",
          "iopub.execute_input": "2025-03-15T17:56:48.195362Z",
          "iopub.status.idle": "2025-03-15T17:56:48.201466Z",
          "shell.execute_reply.started": "2025-03-15T17:56:48.195341Z",
          "shell.execute_reply": "2025-03-15T17:56:48.200595Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Count the number of trainable parameters in the model using the automated function."
      ],
      "metadata": {
        "_uuid": "55fc17f2-60b3-4fdc-a013-56dd43e5334e",
        "_cell_guid": "74099b70-34ed-47f2-a6a6-ed1427f2bfba",
        "trusted": true,
        "collapsed": false,
        "id": "6YUYruSIT-br",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=MLPModel(10000)\n",
        "print(f\"Number of trainable parameters in the model: {model.count_parameters()}\")"
      ],
      "metadata": {
        "_uuid": "9a1d4bd8-d50c-4e61-99fb-b589c8b46a7e",
        "_cell_guid": "99f188f9-e684-427b-9cb4-a7888d0eb5a9",
        "trusted": true,
        "id": "bG7uVdChT6zs",
        "outputId": "e1319138-297e-42e5-bd78-d7f412523cc8",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:48.202478Z",
          "iopub.execute_input": "2025-03-15T17:56:48.202852Z",
          "iopub.status.idle": "2025-03-15T17:56:48.296593Z",
          "shell.execute_reply.started": "2025-03-15T17:56:48.202819Z",
          "shell.execute_reply": "2025-03-15T17:56:48.295974Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of trainable parameters in the model: 5293122\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "_uuid": "3059d1a4-5f35-4643-98d9-a8fa8d205af2",
        "_cell_guid": "6664bc6f-7a12-477a-afdb-0d995f716c68",
        "trusted": true,
        "id": "IcETp7jmQAoH",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:48.297246Z",
          "iopub.execute_input": "2025-03-15T17:56:48.297432Z",
          "iopub.status.idle": "2025-03-15T17:56:48.375348Z",
          "shell.execute_reply.started": "2025-03-15T17:56:48.297415Z",
          "shell.execute_reply": "2025-03-15T17:56:48.374427Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement case 1: Bag-of-words (20%)<br>\n",
        "- Implement the bag-of-words (max_features=10000).<br>\n",
        "- Hint: from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "_uuid": "90118390-cc66-446a-ab03-828cf46f0ef8",
        "_cell_guid": "268d2cf6-c314-4109-9859-7ba2a0f952fb",
        "trusted": true,
        "collapsed": false,
        "id": "MOx3RZAYUCdA",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Bag-of-Words Vectorization\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "\n",
        "# Transforming sentences into BoW features\n",
        "X_train_bow = vectorizer.fit_transform(data1_train['sentence']).toarray()\n",
        "X_val_bow = vectorizer.transform(data1_val['sentence']).toarray()\n",
        "X_test_bow = vectorizer.transform(data1_test['sentence']).toarray()\n",
        "\n",
        "# Converting labels to tensors\n",
        "y_train_bow = torch.tensor(data1_train['label'].values)\n",
        "y_val_bow = torch.tensor(data1_val['label'].values)\n",
        "y_test_bow = torch.tensor(data1_test['label'].values)\n",
        "\n",
        "# Creating DataLoaders for BoW\n",
        "train_dataset_bow = TensorDataset(torch.tensor(X_train_bow, dtype=torch.float32), y_train_bow)\n",
        "val_dataset_bow = TensorDataset(torch.tensor(X_val_bow, dtype=torch.float32), y_val_bow)\n",
        "test_dataset_bow = TensorDataset(torch.tensor(X_test_bow, dtype=torch.float32), y_test_bow)\n",
        "\n",
        "train_loader_bow = DataLoader(train_dataset_bow, batch_size=32, shuffle=True)\n",
        "val_loader_bow = DataLoader(val_dataset_bow, batch_size=32)\n",
        "test_loader_bow = DataLoader(test_dataset_bow, batch_size=32)\n",
        "\n",
        "print(\"Bag-of-Words features prepared.\")"
      ],
      "metadata": {
        "_uuid": "202ae1ab-5266-454c-b960-13a9575ea7f8",
        "_cell_guid": "263c9a79-6ece-4f45-a68b-e96994c5b201",
        "trusted": true,
        "id": "qQ9RPZV1On_Z",
        "outputId": "c0a12976-a88e-48b5-9e59-0d9d52111e6d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:48.378286Z",
          "iopub.execute_input": "2025-03-15T17:56:48.37849Z",
          "iopub.status.idle": "2025-03-15T17:56:49.023699Z",
          "shell.execute_reply.started": "2025-03-15T17:56:48.378473Z",
          "shell.execute_reply": "2025-03-15T17:56:49.022888Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Bag-of-Words features prepared.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>4. Implement case 2: Construct a function to use embeddings on the same model. (20%)<br></B>\n",
        "- Use the model: meta-llama/Llama-3.1-8B or use bert-base-uncased if facing issues with the GPU constraints.\n",
        "- TIPS:<br>\n",
        "You can use the distilled version, gather embeddings for 200 samples, and even reduce the precision to deal with computing issues!\n",
        "- Hints:<br>\n",
        "self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "     self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "     self.embedding_size = self.model.config.hidden_size\n",
        "     self.model_loaded = True"
      ],
      "metadata": {
        "_uuid": "16dbda5b-4a18-4da4-b75a-8eb52929a312",
        "_cell_guid": "3b8cab7d-ec57-4d21-a2e8-71dc0150df88",
        "trusted": true,
        "collapsed": false,
        "id": "Wv6g-_YxULSp",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "class EmbeddingExtractor:\n",
        "    def __init__(self, model_name='bert-base-uncased', device=None):\n",
        "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Initializing tokenizer and model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
        "\n",
        "    def get_embeddings(self, sentences):\n",
        "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(self.device)\n",
        "\n",
        "        # Extracting embeddings using [CLS] token representation\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "\n",
        "        return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "embedding_extractor = EmbeddingExtractor()\n",
        "\n",
        "# Extracting embeddings for train/validation/test datasets\n",
        "X_train_emb = embedding_extractor.get_embeddings(data1_train['sentence'].tolist()[:200])  # First 200 samples due to GPU constraints\n",
        "X_val_emb = embedding_extractor.get_embeddings(data1_val['sentence'].tolist()[:200])\n",
        "X_test_emb = embedding_extractor.get_embeddings(data1_test['sentence'].tolist()[:200])\n",
        "\n",
        "# Convert labels to tensors\n",
        "y_train_emb = torch.tensor(data1_train['label'].values[:200])\n",
        "y_val_emb = torch.tensor(data1_val['label'].values[:200])\n",
        "y_test_emb = torch.tensor(data1_test['label'].values[:200])\n",
        "\n",
        "# Create DataLoaders for embeddings\n",
        "train_dataset_emb = TensorDataset(torch.tensor(X_train_emb, dtype=torch.float32), y_train_emb)\n",
        "val_dataset_emb = TensorDataset(torch.tensor(X_val_emb, dtype=torch.float32), y_val_emb)\n",
        "test_dataset_emb = TensorDataset(torch.tensor(X_test_emb, dtype=torch.float32), y_test_emb)\n",
        "\n",
        "train_loader_emb = DataLoader(train_dataset_emb, batch_size=32, shuffle=True)\n",
        "val_loader_emb = DataLoader(val_dataset_emb, batch_size=32)\n",
        "test_loader_emb = DataLoader(test_dataset_emb, batch_size=32)\n",
        "\n",
        "print(\"Embedding-based features prepared\")"
      ],
      "metadata": {
        "_uuid": "29c25866-1a61-4eb2-b524-bcfc464fc9e1",
        "_cell_guid": "fcb145bf-c1ca-4742-a000-2389cebc8dbd",
        "trusted": true,
        "id": "hwKA5TtmOsrS",
        "outputId": "288e2295-9fa2-48b0-c57b-be4f98bde69f",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:56:49.025662Z",
          "iopub.execute_input": "2025-03-15T17:56:49.025929Z",
          "iopub.status.idle": "2025-03-15T17:57:03.296579Z",
          "shell.execute_reply.started": "2025-03-15T17:56:49.025908Z",
          "shell.execute_reply": "2025-03-15T17:57:03.295754Z"
        },
        "colab": {
          "referenced_widgets": [
            "6c1435ecda7f4ee08d8f6cdb4c666109",
            "036da3de413f4dce807136bbdc568968",
            "bc674252dc36461397eecb5f8e4304a7",
            "f85a9a5272c34ca593b555019049d137",
            "0c432dec5a2b43719e7430def7617ace"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c1435ecda7f4ee08d8f6cdb4c666109"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "036da3de413f4dce807136bbdc568968"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc674252dc36461397eecb5f8e4304a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f85a9a5272c34ca593b555019049d137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c432dec5a2b43719e7430def7617ace"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Embedding-based features prepared\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>5. Train the model with 10 epochs and create the best-performing model (checkpoint.pt) on the Dataset 1. (10%)<br></B>\n",
        "- Get the validation accuracy."
      ],
      "metadata": {
        "_uuid": "bf7c96e7-b78a-4abc-80c9-4c39dfe24e33",
        "_cell_guid": "e3f54780-f735-4403-ade8-d101fcc33874",
        "trusted": true,
        "collapsed": false,
        "id": "laRlTAuMUaR3",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "#Function to save the best model at a checkpoint in compressed form\n",
        "def save_checkpoint(state,filename,compress=True):\n",
        "    if compress:\n",
        "        with gzip.open(filename + '.gz', 'wb') as f:\n",
        "            torch.save(state, f)\n",
        "    else:\n",
        "        torch.save(state, filename)\n",
        "\n",
        "#Function to load saved best model from a checkpoint\n",
        "def load_checkpoint(filename, compress=True):\n",
        "    if compress:\n",
        "        with gzip.open(filename + '.gz', 'rb') as f:\n",
        "            state = torch.load(f)\n",
        "    else:\n",
        "        state = torch.load(filename)\n",
        "    return state"
      ],
      "metadata": {
        "_uuid": "79bac9c6-ebe5-47cc-aaec-5f2174362469",
        "_cell_guid": "521824f2-1e8d-48af-830e-f05d02797553",
        "trusted": true,
        "id": "R_lZeH0Z-5x4",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:03.297486Z",
          "iopub.execute_input": "2025-03-15T17:57:03.29818Z",
          "iopub.status.idle": "2025-03-15T17:57:03.303345Z",
          "shell.execute_reply.started": "2025-03-15T17:57:03.298147Z",
          "shell.execute_reply": "2025-03-15T17:57:03.302183Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to plot loss curves and save to tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(train_losses, val_losses,title):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    axes[0].plot(epochs, train_losses, marker='o', linestyle=\"--\", color='b')\n",
        "    axes[0].set_title(f\"{title} - Train Loss Curve\")\n",
        "    axes[0].set_xlabel(\"Epochs\")\n",
        "    axes[0].set_ylabel(\"Train Loss\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(epochs, val_losses, marker='s', linestyle=\"-\", color='m')\n",
        "    axes[1].set_title(f\"{title} - Valid Loss Curve\")\n",
        "    axes[1].set_xlabel(\"Epochs\")\n",
        "    axes[1].set_ylabel(\"Validation Loss\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "_uuid": "52df9be7-ae35-4e1e-8da8-c030d343bab1",
        "_cell_guid": "6fa4cf08-7651-49bb-bd72-2e3228bde00f",
        "trusted": true,
        "id": "yVa2ZCiEBO5-",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:03.304093Z",
          "iopub.execute_input": "2025-03-15T17:57:03.304301Z",
          "iopub.status.idle": "2025-03-15T17:57:03.324375Z",
          "shell.execute_reply.started": "2025-03-15T17:57:03.304284Z",
          "shell.execute_reply": "2025-03-15T17:57:03.323594Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer,epochs,save_path,model_title,dataset,resume=False):\n",
        "    writer=SummaryWriter(f'runs/{model_title}/{dataset}')\n",
        "\n",
        "    dummy_input = torch.randn(1, model.fc1.in_features).to(device)  # Dummy input for logging the graph\n",
        "    writer.add_graph(model, dummy_input)\n",
        "\n",
        "\n",
        "    best_val_acc=0.0\n",
        "    if resume:\n",
        "        checkpoint = load_checkpoint(save_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_acc=correct/len(val_loader.dataset)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
        "\n",
        "        hyperparams = {\n",
        "            'input_size': model.fc1.in_features,\n",
        "            'hidden_sizes': str([model.fc1.out_features, model.fc2.out_features, model.fc3.out_features, model.fc4.out_features]),  # Convert list to string\n",
        "            'output_size': model.fc5.out_features,\n",
        "            'dropout_prob': float(model.dropout.p),\n",
        "            'learning_rate': float(optimizer.param_groups[0]['lr']),\n",
        "            'epochs': int(epochs)\n",
        "        }\n",
        "\n",
        "        writer.add_hparams(\n",
        "            hparam_dict=hyperparams,\n",
        "            metric_dict={\n",
        "                'Loss/val': avg_val_loss,\n",
        "                'Accuracy/val': val_acc\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc=val_acc\n",
        "            checkpoint = {\n",
        "                'model_state_dict': model.state_dict(),\n",
        "            }\n",
        "            save_checkpoint(checkpoint, save_path)\n",
        "\n",
        "    writer.add_figure('Loss Curves', plot_loss_curves(train_losses, val_losses,model_title), global_step=0)\n",
        "    writer.close()\n",
        "    print(hyperparams)"
      ],
      "metadata": {
        "_uuid": "ef53741d-4c26-49b2-8faa-fbb5aa20e390",
        "_cell_guid": "04d40668-ac5b-4535-bb03-340dbaf5b22b",
        "trusted": true,
        "id": "yttoZ4qDO1FB",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:03.325055Z",
          "iopub.execute_input": "2025-03-15T17:57:03.325271Z",
          "iopub.status.idle": "2025-03-15T17:57:03.340635Z",
          "shell.execute_reply.started": "2025-03-15T17:57:03.325252Z",
          "shell.execute_reply": "2025-03-15T17:57:03.339944Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "_uuid": "fe2c0830-5170-4bea-b12b-6b8a47ce89c8",
        "_cell_guid": "d9ba65e0-d2b3-4ff7-972d-06de7026cb72",
        "trusted": true,
        "id": "ycPJ8BN8QTNC",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:03.341283Z",
          "iopub.execute_input": "2025-03-15T17:57:03.341466Z",
          "iopub.status.idle": "2025-03-15T17:57:03.360112Z",
          "shell.execute_reply.started": "2025-03-15T17:57:03.34145Z",
          "shell.execute_reply": "2025-03-15T17:57:03.359479Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining device globally\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instantiating MLP model for BoW features (input size is 10000 for BoW)\n",
        "model_bow = MLPModel(input_size=10000).to(device)\n",
        "\n",
        "criterion_bow = nn.CrossEntropyLoss()\n",
        "optimizer_bow = torch.optim.Adam(model_bow.parameters(), lr=0.001)\n",
        "\n",
        "#training the model and saving the best model at checkpoint\n",
        "train_model(model_bow, train_loader_bow, val_loader_bow, criterion_bow,optimizer_bow,10,'checkpoint_bow.pt','Bag-of-Words','Dataset1')\n",
        "test_model(model_bow, test_loader_bow)"
      ],
      "metadata": {
        "_uuid": "fc5b1ca0-7825-4542-a1a4-2397829fcc98",
        "_cell_guid": "eef139cb-18d5-4419-94f6-010a11d650f1",
        "trusted": true,
        "id": "PUVXCRe2O7ak",
        "outputId": "719aa9b2-ccd1-4bf8-95c2-97be1e962f41",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:03.360765Z",
          "iopub.execute_input": "2025-03-15T17:57:03.360959Z",
          "iopub.status.idle": "2025-03-15T17:57:16.951831Z",
          "shell.execute_reply.started": "2025-03-15T17:57:03.360935Z",
          "shell.execute_reply": "2025-03-15T17:57:16.950907Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'input_size': 10000, 'hidden_sizes': '[512, 256, 128, 64]', 'output_size': 2, 'dropout_prob': 0.3, 'learning_rate': 0.001, 'epochs': 10}\nTest Accuracy: 78.80%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating MLP model for embeddings (input size is 768 for BERT embeddings)\n",
        "model_emb = MLPModel(input_size=768).to(device)\n",
        "\n",
        "criterion_emb = nn.CrossEntropyLoss()\n",
        "optimizer_emb = torch.optim.Adam(model_emb.parameters(), lr=0.001)\n",
        "\n",
        "#training the model and saving the best model at checkpoint\n",
        "train_model(model_emb, train_loader_emb, val_loader_emb, criterion_emb, optimizer_emb,10,'checkpoint_emb.pt','Embeddings','Dataset1')\n",
        "test_model(model_emb, test_loader_emb)"
      ],
      "metadata": {
        "_uuid": "3b3868ac-866b-4b1e-919b-623cb7b678d9",
        "_cell_guid": "b7a4031e-ea8a-4f7c-9a00-3174f1be52f8",
        "trusted": true,
        "id": "ITR1qn7qQ3eO",
        "outputId": "3a07105c-0f6e-4500-b7fd-10fe362a2f42",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:16.952514Z",
          "iopub.execute_input": "2025-03-15T17:57:16.952767Z",
          "iopub.status.idle": "2025-03-15T17:57:17.959751Z",
          "shell.execute_reply.started": "2025-03-15T17:57:16.952745Z",
          "shell.execute_reply": "2025-03-15T17:57:17.958111Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'input_size': 768, 'hidden_sizes': '[512, 256, 128, 64]', 'output_size': 2, 'dropout_prob': 0.3, 'learning_rate': 0.001, 'epochs': 10}\nTest Accuracy: 75.50%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>6. Use the checkpoint from before and train on the IMDB dataset (Dataset 2). (10%)<br></B>\n",
        "- Use the following parameters:<br>\n",
        "criterion = nn.CrossEntropyLoss()<br>\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Smaller learning rate"
      ],
      "metadata": {
        "_uuid": "76d67257-a839-461d-83c2-9399c4162554",
        "_cell_guid": "bf7fe654-1aaf-4ddf-a9a1-3a2887415f18",
        "trusted": true,
        "collapsed": false,
        "id": "xUDGMwNuUs_F",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Function to get encoding for labels\n",
        "def encode_labels(series):\n",
        "    label_encoder=LabelEncoder()\n",
        "    encoded_labels=label_encoder.fit_transform(series.astype(str))\n",
        "    return torch.tensor(encoded_labels,dtype=torch.long)"
      ],
      "metadata": {
        "_uuid": "720e7f1c-fbb4-4193-9f8b-0c8034152a0a",
        "_cell_guid": "169adb8a-64e9-4e34-ae94-96a5efdcc3cf",
        "trusted": true,
        "id": "X19gmxqHbldU",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:17.960666Z",
          "iopub.execute_input": "2025-03-15T17:57:17.960962Z",
          "iopub.status.idle": "2025-03-15T17:57:18.424495Z",
          "shell.execute_reply.started": "2025-03-15T17:57:17.96094Z",
          "shell.execute_reply": "2025-03-15T17:57:18.423501Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing IMDB dataset to train of Bag-of-Words Model"
      ],
      "metadata": {
        "_uuid": "86392abf-a32e-44b9-8e02-b0896776da75",
        "_cell_guid": "8968cf64-d331-4218-b324-b6bbf3c3e5a9",
        "trusted": true,
        "collapsed": false,
        "id": "8hDh9BJ8cp7d",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "\n",
        "X_train_bow = vectorizer.fit_transform(data2_train['review']).toarray()\n",
        "X_val_bow = vectorizer.transform(data2_val['review']).toarray()\n",
        "X_test_bow = vectorizer.transform(data2_test['review']).toarray()\n",
        "\n",
        "# Converting labels to tensors\n",
        "y_train_bow = encode_labels(data2_train['sentiment'].values)\n",
        "y_val_bow = encode_labels(data2_val['sentiment'].values)\n",
        "y_test_bow = encode_labels(data2_test['sentiment'].values)\n",
        "\n",
        "# Creating DataLoaders for BoW\n",
        "train_dataset_bow = TensorDataset(torch.tensor(X_train_bow, dtype=torch.float32), y_train_bow)\n",
        "val_dataset_bow = TensorDataset(torch.tensor(X_val_bow, dtype=torch.float32), y_val_bow)\n",
        "test_dataset_bow = TensorDataset(torch.tensor(X_test_bow, dtype=torch.float32), y_test_bow)\n",
        "\n",
        "train_loader_bow = DataLoader(train_dataset_bow, batch_size=32, shuffle=True)\n",
        "val_loader_bow = DataLoader(val_dataset_bow, batch_size=32)\n",
        "test_loader_bow = DataLoader(test_dataset_bow, batch_size=32)"
      ],
      "metadata": {
        "_uuid": "050eb9d7-adab-41cf-8b8b-24eaf8280855",
        "_cell_guid": "d79400c1-014a-4248-97f3-6e13ebdac9dd",
        "trusted": true,
        "id": "OfQuNvXYUTIR",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:18.425337Z",
          "iopub.execute_input": "2025-03-15T17:57:18.425564Z",
          "iopub.status.idle": "2025-03-15T17:57:29.968429Z",
          "shell.execute_reply.started": "2025-03-15T17:57:18.425544Z",
          "shell.execute_reply": "2025-03-15T17:57:29.967724Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing IMDB dataset to train of Embeddings Model"
      ],
      "metadata": {
        "_uuid": "d5196228-ea67-4941-b3cd-e073d66d9c86",
        "_cell_guid": "a4170d8f-13ff-4ba9-81c8-b357d77b0aaa",
        "trusted": true,
        "collapsed": false,
        "id": "yjJvSsOcc3ye",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_extractor = EmbeddingExtractor()\n",
        "\n",
        "# Extracting embeddings for train/validation/test datasets\n",
        "X_train_emb = embedding_extractor.get_embeddings(data2_train['review'].tolist()[:200])  # First 200 samples due to GPU constraints\n",
        "X_val_emb = embedding_extractor.get_embeddings(data2_val['review'].tolist()[:200])\n",
        "X_test_emb = embedding_extractor.get_embeddings(data2_test['review'].tolist()[:200])\n",
        "\n",
        "# Convert labels to tensors\n",
        "y_train_emb = encode_labels(data2_train['sentiment'].values[:200])\n",
        "y_val_emb = encode_labels(data2_val['sentiment'].values[:200])\n",
        "y_test_emb = encode_labels(data2_test['sentiment'].values[:200])\n",
        "\n",
        "# Create DataLoaders for embeddings\n",
        "train_dataset_emb = TensorDataset(torch.tensor(X_train_emb, dtype=torch.float32), y_train_emb)\n",
        "val_dataset_emb = TensorDataset(torch.tensor(X_val_emb, dtype=torch.float32), y_val_emb)\n",
        "test_dataset_emb = TensorDataset(torch.tensor(X_test_emb, dtype=torch.float32), y_test_emb)\n",
        "\n",
        "train_loader_emb = DataLoader(train_dataset_emb, batch_size=32, shuffle=True)\n",
        "val_loader_emb = DataLoader(val_dataset_emb, batch_size=32)\n",
        "test_loader_emb = DataLoader(test_dataset_emb, batch_size=32)"
      ],
      "metadata": {
        "_uuid": "9d8d170c-7a38-4446-a508-c867e0839a71",
        "_cell_guid": "96e0191c-f8cd-4639-818b-6121394808df",
        "trusted": true,
        "id": "EWCyejijVg6F",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:29.969195Z",
          "iopub.execute_input": "2025-03-15T17:57:29.969401Z",
          "iopub.status.idle": "2025-03-15T17:57:48.630609Z",
          "shell.execute_reply.started": "2025-03-15T17:57:29.969383Z",
          "shell.execute_reply": "2025-03-15T17:57:48.629698Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Compute the validation loss and accuracy on the validation set of the Dataset 1 and IMDB dataset. (10%)"
      ],
      "metadata": {
        "_uuid": "e600562f-c048-4862-b414-98af9ae8a8a8",
        "_cell_guid": "c4a03fb2-337e-4ca6-801a-56bff3727ea6",
        "trusted": true,
        "collapsed": false,
        "id": "Oim-JjtLU218",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Bag-of-Words Model"
      ],
      "metadata": {
        "_uuid": "1f6cc4df-0d42-4d89-90ac-631cc5159b9e",
        "_cell_guid": "118b8c61-2715-41d4-8e0d-f5626d12568d",
        "trusted": true,
        "collapsed": false,
        "id": "W92GZIqAdDQY",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining device globally\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instantiating MLP model for BoW features (input size is 10000 for BoW)\n",
        "model_bow = MLPModel(input_size=10000).to(device)\n",
        "\n",
        "criterion_bow = nn.CrossEntropyLoss()\n",
        "optimizer_bow = torch.optim.Adam(model_bow.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(model_bow, train_loader_bow, val_loader_bow, criterion_bow, optimizer_bow,10,'checkpoint_bow.pt','Bag-of-Words','IMDB_dataset',True)\n",
        "test_model(model_bow, test_loader_bow)"
      ],
      "metadata": {
        "_uuid": "79b7754c-8d2e-47b8-935f-1b52fbc7938b",
        "_cell_guid": "3c4a4555-142b-4a43-9847-6ee7bef68e3c",
        "trusted": true,
        "id": "7IHVrxB1WRe6",
        "outputId": "f2223926-f1d7-42ea-8b09-65bdf06dc16a",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:57:48.631554Z",
          "iopub.execute_input": "2025-03-15T17:57:48.631899Z",
          "iopub.status.idle": "2025-03-15T17:58:42.230028Z",
          "shell.execute_reply.started": "2025-03-15T17:57:48.631868Z",
          "shell.execute_reply": "2025-03-15T17:58:42.229161Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-10-13a70b0b6b2e>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'input_size': 10000, 'hidden_sizes': '[512, 256, 128, 64]', 'output_size': 2, 'dropout_prob': 0.3, 'learning_rate': 0.0001, 'epochs': 10}\nTest Accuracy: 87.93%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Embeddings Model"
      ],
      "metadata": {
        "_uuid": "910ebe55-7e2a-4b02-8667-55eb34a679c7",
        "_cell_guid": "542e6a3c-acfa-45e3-a877-6f76dd2d4668",
        "trusted": true,
        "collapsed": false,
        "id": "vcZYtRWBdHNe",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating MLP model for embeddings (input size is 768 for BERT embeddings)\n",
        "model_emb = MLPModel(input_size=X_train_emb.shape[1]).to(device)\n",
        "\n",
        "criterion_emb = nn.CrossEntropyLoss()\n",
        "optimizer_emb = torch.optim.Adam(model_emb.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(model_emb, train_loader_emb, val_loader_emb, criterion_emb, optimizer_emb,10,'checkpoint_emb.pt','Embeddings','IMDB_dataset',True)\n",
        "test_model(model_emb, test_loader_emb)"
      ],
      "metadata": {
        "_uuid": "5235ed2b-be04-43a6-9079-22ff60a64292",
        "_cell_guid": "755d397e-bc4e-4553-badd-01a583c9bb8e",
        "trusted": true,
        "id": "y9OtLLtiWjRE",
        "outputId": "29b2c5b4-58c0-41a2-e0c8-5cda5dbd91ca",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:42.231068Z",
          "iopub.execute_input": "2025-03-15T17:58:42.231443Z",
          "iopub.status.idle": "2025-03-15T17:58:43.234686Z",
          "shell.execute_reply.started": "2025-03-15T17:58:42.23141Z",
          "shell.execute_reply": "2025-03-15T17:58:43.233952Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-10-13a70b0b6b2e>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'input_size': 768, 'hidden_sizes': '[512, 256, 128, 64]', 'output_size': 2, 'dropout_prob': 0.3, 'learning_rate': 0.0001, 'epochs': 10}\nTest Accuracy: 76.50%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Submission Requirements<br>\n",
        "- Python code for training, testing, and evaluation.\n",
        "- Screenshots of the following displaying:<br>\n",
        "Model architecture.<br>\n",
        "Hyperparameters.<br>\n",
        "Logged metrics.<br>\n",
        "Final evaluation results.<br>\n",
        "Confusion matrix visualization.<br>\n",
        "Training and validation loss curves.<br>"
      ],
      "metadata": {
        "_uuid": "ac271e57-6c62-4fae-ae29-31d556736bdf",
        "_cell_guid": "96e089d0-db43-4971-ae5e-e2e0f1396d53",
        "trusted": true,
        "collapsed": false,
        "id": "3PBKw-5fU--v",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = load_checkpoint(\"checkpoint_bow.pt\")\n",
        "model_bow.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "checkpoint = load_checkpoint(\"checkpoint_emb.pt\")\n",
        "model_emb.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "_uuid": "cee52260-491e-4220-bf2d-c3fcd58a3610",
        "_cell_guid": "6c652ff4-90da-460b-b061-c93e6799b151",
        "trusted": true,
        "id": "sH3a14CvaPxc",
        "outputId": "512e041e-d56b-41dc-eef1-3d261b38066c",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:43.235481Z",
          "iopub.execute_input": "2025-03-15T17:58:43.235724Z",
          "iopub.status.idle": "2025-03-15T17:58:44.646114Z",
          "shell.execute_reply.started": "2025-03-15T17:58:43.235691Z",
          "shell.execute_reply": "2025-03-15T17:58:44.64529Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-10-13a70b0b6b2e>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(f)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final evaluation results."
      ],
      "metadata": {
        "_uuid": "20096743-7dbc-430b-98ec-430767145049",
        "_cell_guid": "880b9f53-9735-431a-839f-ff5eb9980d4f",
        "trusted": true,
        "collapsed": false,
        "id": "Nk7BwGhAVTKB",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "import pandas as pd\n",
        "\n",
        "def evaluation_metrics(model,loader,model_title):\n",
        "    writer=SummaryWriter(f'runs/{model_title}')\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\")  # Weighted for class imbalance\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    writer.add_scalar('Final Evaluation/Accuracy', accuracy, 0)\n",
        "    writer.add_scalar('Final Evaluation/Precision', precision, 0)\n",
        "    writer.add_scalar('Final Evaluation/Recall', recall, 0)\n",
        "    writer.add_scalar('Final Evaluation/F1-Score', f1, 0)\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    result={\n",
        "        \"Metrics\":['Accuracy','Precision','Recall','F1-Score'],\n",
        "        \"Values\":[accuracy,precision,recall,f1]\n",
        "    }\n",
        "    return pd.DataFrame(result).set_index(\"Metrics\")"
      ],
      "metadata": {
        "_uuid": "26d9ffd4-fe6f-41ca-abb1-9e50889ac635",
        "_cell_guid": "4f14178a-1690-4a79-bdba-94e185932ea8",
        "trusted": true,
        "id": "q4YFy788aXSo",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:44.646972Z",
          "iopub.execute_input": "2025-03-15T17:58:44.647197Z",
          "iopub.status.idle": "2025-03-15T17:58:44.653673Z",
          "shell.execute_reply.started": "2025-03-15T17:58:44.647179Z",
          "shell.execute_reply": "2025-03-15T17:58:44.653068Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "results=evaluation_metrics(model_bow,test_loader_bow,'Bag-of-Words')\n",
        "results"
      ],
      "metadata": {
        "_uuid": "0e3a6725-9158-4c9e-b1ad-b62b269764ba",
        "_cell_guid": "cf0fef88-67ed-4ab0-b732-df5736d89c86",
        "trusted": true,
        "id": "1gTR9wdEVbOT",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:44.654469Z",
          "iopub.execute_input": "2025-03-15T17:58:44.654657Z",
          "iopub.status.idle": "2025-03-15T17:58:45.150371Z",
          "shell.execute_reply.started": "2025-03-15T17:58:44.65464Z",
          "shell.execute_reply": "2025-03-15T17:58:45.149459Z"
        },
        "outputId": "159c9885-7ab2-4c38-9435-103bc2b5d89c"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              Values\nMetrics             \nAccuracy   89.320000\nPrecision   0.893463\nRecall      0.893200\nF1-Score    0.893194",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Values</th>\n    </tr>\n    <tr>\n      <th>Metrics</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>89.320000</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.893463</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.893200</td>\n    </tr>\n    <tr>\n      <th>F1-Score</th>\n      <td>0.893194</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "results=evaluation_metrics(model_emb,test_loader_emb,'Embeddings')\n",
        "results"
      ],
      "metadata": {
        "_uuid": "f6bb243c-7f0b-4e40-911e-1273ef4d3de3",
        "_cell_guid": "f2add8f9-d4c2-4c84-9583-f490844695cb",
        "trusted": true,
        "id": "CxA67hCrVbKw",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.151196Z",
          "iopub.execute_input": "2025-03-15T17:58:45.151458Z",
          "iopub.status.idle": "2025-03-15T17:58:45.173515Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.151423Z",
          "shell.execute_reply": "2025-03-15T17:58:45.172693Z"
        },
        "outputId": "4f72b686-4820-4348-8f52-63e2373c8984"
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              Values\nMetrics             \nAccuracy   76.000000\nPrecision   0.765210\nRecall      0.760000\nF1-Score    0.759856",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Values</th>\n    </tr>\n    <tr>\n      <th>Metrics</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>76.000000</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.765210</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.760000</td>\n    </tr>\n    <tr>\n      <th>F1-Score</th>\n      <td>0.759856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix visualization."
      ],
      "metadata": {
        "_uuid": "092a4ff9-d799-4e39-bb1a-868597641d17",
        "_cell_guid": "82b2d9a4-de18-4532-bccf-6cd9b041edb7",
        "trusted": true,
        "collapsed": false,
        "id": "CFRe-5DRVtuj",
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_names_from_loader(loader):\n",
        "    dataset = loader.dataset\n",
        "\n",
        "    if hasattr(dataset, 'classes'):\n",
        "        return dataset.classes\n",
        "    elif hasattr(dataset, 'class_to_idx'):\n",
        "        return list(dataset.class_to_idx.keys())"
      ],
      "metadata": {
        "_uuid": "5de2abf2-95b3-414b-9292-bd35eb64881c",
        "_cell_guid": "93212df1-f51f-4ab9-acbc-14dca339a725",
        "trusted": true,
        "id": "ziQcWj2AWspP",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.174316Z",
          "iopub.execute_input": "2025-03-15T17:58:45.174522Z",
          "iopub.status.idle": "2025-03-15T17:58:45.178348Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.174504Z",
          "shell.execute_reply": "2025-03-15T17:58:45.17741Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model, loader, class_labels, model_name):\n",
        "    writer=SummaryWriter(f'runs/{model_name}')\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Display confusion matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp.plot(cmap=\"Blues\", values_format=\"d\",ax=ax)\n",
        "    plt.title(f\"Confusion Matrix - {model_name}_Model\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    writer.add_figure(f'Confusion Matrix',fig, global_step=0)  # Save figure\n",
        "    plt.close(fig)\n",
        "    writer.close()"
      ],
      "metadata": {
        "_uuid": "814fafdb-0883-43cd-bff6-c4c7b406d6dc",
        "_cell_guid": "7f1a25fb-43a9-41c3-b31f-2b1684eb0490",
        "trusted": true,
        "id": "Eed2UgHLajoO",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.181433Z",
          "iopub.execute_input": "2025-03-15T17:58:45.181627Z",
          "iopub.status.idle": "2025-03-15T17:58:45.193391Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.18161Z",
          "shell.execute_reply": "2025-03-15T17:58:45.192789Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_bow,test_loader_bow,get_class_names_from_loader(test_loader_bow),\"Bag-of-Words\")"
      ],
      "metadata": {
        "_uuid": "8ce5776a-1fd1-4148-9348-d386de9c4649",
        "_cell_guid": "96e1074b-c79d-4cb7-abc1-45c23ca00356",
        "trusted": true,
        "id": "29mMdXtsVxPs",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.194489Z",
          "iopub.execute_input": "2025-03-15T17:58:45.194811Z",
          "iopub.status.idle": "2025-03-15T17:58:45.826998Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.194789Z",
          "shell.execute_reply": "2025-03-15T17:58:45.826061Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(model_emb,test_loader_emb,get_class_names_from_loader(test_loader_emb),\"Embeddings\")"
      ],
      "metadata": {
        "_uuid": "9707659a-3490-458b-b3a4-39e08442f347",
        "_cell_guid": "78e75115-7fa8-473d-b5dc-527f00257646",
        "trusted": true,
        "id": "UsJuKAXLV-BN",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.827834Z",
          "iopub.execute_input": "2025-03-15T17:58:45.828086Z",
          "iopub.status.idle": "2025-03-15T17:58:45.989692Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.828065Z",
          "shell.execute_reply": "2025-03-15T17:58:45.98872Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "output_dir = \"/kaggle/working/runs\"\n",
        "zip_path = \"/kaggle/working/runs.zip\"\n",
        "\n",
        "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', output_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T17:58:45.990659Z",
          "iopub.execute_input": "2025-03-15T17:58:45.991014Z",
          "iopub.status.idle": "2025-03-15T17:58:46.018122Z",
          "shell.execute_reply.started": "2025-03-15T17:58:45.990984Z",
          "shell.execute_reply": "2025-03-15T17:58:46.017293Z"
        },
        "id": "SURdnWssB0_A",
        "outputId": "9512e30d-d5e0-4db6-8992-db5cef90565f"
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/runs.zip'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}